{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36355109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You requested to import horovod which is missing or not supported for your OS.\n",
      "You requested to import horovod which is missing or not supported for your OS.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "PROJ_ROOT = \".\"\n",
    "sys.path.insert(0, PROJ_ROOT)\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "from core.gdrn_modeling.main_gdrn import setup\n",
    "\n",
    "from core.utils.default_args_setup import my_default_argument_parser, my_default_setup\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from detectron2.data import MetadataCatalog\n",
    "from core.gdrn_modeling.data_loader import build_gdrn_train_loader, build_gdrn_test_loader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1981cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[1019_023254@core/gdrn_modeling/main_gdrn.py:72]\u001b[0m optimizer_cfg: {'type': 'Ranger', 'lr': 0.0001, 'weight_decay': 0}\n",
      "\u001b[33m[1019_023254@core/gdrn_modeling/datasets/airplane.py:114]\u001b[0m \u001b[5m\u001b[33mDBG \u001b[0mregister dataset: airplane\n",
      "\u001b[32m[10/19 02:32:54 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/19 02:32:54 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -----------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.6.15 | packaged by conda-forge | (default, Dec  3 2021, 18:49:41) [GCC 9.4.0]\n",
      "numpy                   1.19.2\n",
      "detectron2              0.3 @/home/tianyou_zhang/Project/detectron2/detectron2\n",
      "Compiler                GCC 7.5\n",
      "CUDA compiler           CUDA 11.7\n",
      "detectron2 arch flags   7.5\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.6.0 @/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.4.0\n",
      "torchvision             0.7.0 @/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\n",
      "fvcore                  0.1.5.post20221221\n",
      "cv2                     4.5.5\n",
      "----------------------  -----------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[10/19 02:32:54 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/airplane.py', dist_url='tcp://127.0.0.1:62712', eval_only=False, fp16_allreduce=False, machine_rank=0, num_gpus=1, num_machines=1, opts=None, resume=False, use_adasum=False, use_hvd=False)\n",
      "\u001b[32m[10/19 02:32:54 detectron2]: \u001b[0mContents of args.config_file=/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/airplane.py:\n",
      "OUTPUT_ROOT = '/home/tianyou_zhang/Project/NVR-Net/gdr_normal_NVR_Net/'\n",
      "OUTPUT_DIR = '/home/tianyou_zhang/Project/NVR-Net/gdr_normal_NVR_Net/output/gdrn/airplane/a6_cPnP_airplane_norm_23'\n",
      "EXP_NAME = ''\n",
      "DEBUG = False\n",
      "SEED = -1\n",
      "CUDNN_BENCHMARK = True\n",
      "VIS_PERIOD = 0\n",
      "INPUT = dict(\n",
      "    FORMAT='BGR',\n",
      "    MIN_SIZE_TRAIN=(1080, ),\n",
      "    MAX_SIZE_TRAIN=1920,\n",
      "    MIN_SIZE_TRAIN_SAMPLING='choice',\n",
      "    MIN_SIZE_TEST=1080,\n",
      "    MAX_SIZE_TEST=1920,\n",
      "    WITH_DEPTH=False,\n",
      "    AUG_DEPTH=False,\n",
      "    COLOR_AUG_PROB=0.0,\n",
      "    COLOR_AUG_TYPE='code',\n",
      "    COLOR_AUG_CODE=\n",
      "    'Sequential([Sometimes(0.4, CoarseDropout( p=0.1, size_percent=0.05) ),Sometimes(0.5, GaussianBlur(np.random.rand())),Sometimes(0.5, Add((-20, 20), per_channel=0.3)),Sometimes(0.4, Invert(0.20, per_channel=True)),Sometimes(0.5, Multiply((0.7, 1.4), per_channel=0.8)),Sometimes(0.5, Multiply((0.7, 1.4))),Sometimes(0.5, ContrastNormalization((0.5, 2.0), per_channel=0.3))], random_order=False)',\n",
      "    COLOR_AUG_SYN_ONLY=False,\n",
      "    BG_TYPE='coco',\n",
      "    BG_IMGS_ROOT='datasets/background/',\n",
      "    NUM_BG_IMGS=10000,\n",
      "    CHANGE_BG_PROB=0.5,\n",
      "    TRUNCATE_FG=False,\n",
      "    BG_KEEP_ASPECT_RATIO=True,\n",
      "    DZI_TYPE='uniform',\n",
      "    DZI_PAD_SCALE=1.2,\n",
      "    DZI_SCALE_RATIO=0.025,\n",
      "    DZI_SHIFT_RATIO=0.025,\n",
      "    SMOOTH_XYZ=False,\n",
      "    SMOOTH_NORM=False,\n",
      "    VIDEO=None,\n",
      "    FLIP_PROB=0.5,\n",
      "    FIXED_FOCAL_LENGTH=100,\n",
      "    XY_SCALE_RATIO=1,\n",
      "    Z_SCALE_RATIO=0.001)\n",
      "DATASETS = dict(\n",
      "    TRAIN=('airplane',),\n",
      "    TRAIN2=(),\n",
      "    TRAIN2_RATIO=0.0,\n",
      "    PROPOSAL_FILES_TRAIN=(),\n",
      "    PRECOMPUTED_PROPOSAL_TOPK_TRAIN=2000,\n",
      "    TEST=('airplane',),\n",
      "    PROPOSAL_FILES_TEST=(),\n",
      "    PRECOMPUTED_PROPOSAL_TOPK_TEST=1000,\n",
      "    DET_FILES_TEST=(\n",
      "        '/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/you3/bbox.json',\n",
      "        # 'datasets/airplane/training/bboxes/yolov3_results.json',\n",
      "    ),\n",
      "    DET_TOPK_PER_OBJ=1,\n",
      "    DET_THR=0.0,\n",
      "    SYM_OBJS=[])\n",
      "DATALOADER = dict(\n",
      "    NUM_WORKERS=32,\n",
      "    ASPECT_RATIO_GROUPING=False,\n",
      "    SAMPLER_TRAIN='TrainingSampler',\n",
      "    REPEAT_THRESHOLD=0.0,\n",
      "    FILTER_EMPTY_ANNOTATIONS=True,\n",
      "    FILTER_EMPTY_DETS=True,\n",
      "    FILTER_VISIB_THR=0.0)\n",
      "SOLVER = dict(\n",
      "    IMS_PER_BATCH=48,\n",
      "    TOTAL_EPOCHS=960,\n",
      "    OPTIMIZER_CFG=dict(type='Ranger', lr=0.0001, weight_decay=0),\n",
      "    GAMMA=0.1,\n",
      "    BIAS_LR_FACTOR=1.0,\n",
      "    LR_SCHEDULER_NAME='flat_and_anneal',\n",
      "    WARMUP_METHOD='linear',\n",
      "    WARMUP_FACTOR=0.001,\n",
      "    WARMUP_ITERS=1000,\n",
      "    ANNEAL_METHOD='cosine',\n",
      "    ANNEAL_POINT=0.3,\n",
      "    POLY_POWER=0.9,\n",
      "    REL_STEPS=(0.5, 0.75),\n",
      "    CHECKPOINT_PERIOD=20,\n",
      "    CHECKPOINT_BY_EPOCH=True,\n",
      "    MAX_TO_KEEP=1,\n",
      "    AMP=dict(ENABLED=False),\n",
      "    WEIGHT_DECAY=0,\n",
      "    OPTIMIZER_NAME='Ranger',\n",
      "    BASE_LR=0.0001,\n",
      "    MOMENTUM=0.9)\n",
      "TRAIN = dict(PRINT_FREQ=100, VERBOSE=False, VIS=False, VIS_IMG=False)\n",
      "VAL = dict(\n",
      "    DATASET_NAME='lm',\n",
      "    SCRIPT_PATH='lib/pysixd/scripts/eval_pose_results_more.py',\n",
      "    RESULTS_PATH='',\n",
      "    TARGETS_FILENAME='lm_test_targets_bb8.json',\n",
      "    ERROR_TYPES='ad,rete,re,te,proj',\n",
      "    RENDERER_TYPE='cpp',\n",
      "    SPLIT='test',\n",
      "    SPLIT_TYPE='bb8',\n",
      "    N_TOP=1,\n",
      "    EVAL_CACHED=False,\n",
      "    SCORE_ONLY=False,\n",
      "    EVAL_PRINT_ONLY=False,\n",
      "    EVAL_PRECISION=False,\n",
      "    USE_BOP=False)\n",
      "TEST = dict(\n",
      "    EVAL_PERIOD=0,\n",
      "    VIS=False,\n",
      "    TEST_BBOX_TYPE='est',\n",
      "    PRECISE_BN=dict(ENABLED=False, NUM_ITER=200),\n",
      "    AMP_TEST=False,\n",
      "    USE_PNP=False,\n",
      "    PNP_TYPE='ransac_pnp',\n",
      "    OUTPUT_INTERMEDIATE_FEATURE=False,\n",
      "    USE_SVD=False,\n",
      "    SVD_TYPE='all_once',\n",
      "    SAVE_NORMAL=False)\n",
      "MODEL = dict(\n",
      "    DEVICE='cuda',\n",
      "    WEIGHTS='',\n",
      "    PIXEL_MEAN=[0.0, 0.0, 0.0],\n",
      "    PIXEL_STD=[255.0, 255.0, 255.0],\n",
      "    LOAD_DETS_TEST=True,\n",
      "    CDPN=dict(\n",
      "        NAME='GDRN',\n",
      "        TASK='rot',\n",
      "        USE_MTL=False,\n",
      "        BACKBONE=dict(\n",
      "            PRETRAINED='torchvision://resnet18',\n",
      "            ARCH='resnet',\n",
      "            NUM_LAYERS=18,\n",
      "            INPUT_CHANNEL=3,\n",
      "            INPUT_RES=256,\n",
      "            OUTPUT_RES=64,\n",
      "            FREEZE=False),\n",
      "        ROT_HEAD=dict(\n",
      "            FREEZE=False,\n",
      "            ROT_CONCAT=False,\n",
      "            XYZ_BIN=64,\n",
      "            NUM_LAYERS=3,\n",
      "            NUM_FILTERS=256,\n",
      "            CONV_KERNEL_SIZE=3,\n",
      "            NORM='BN',\n",
      "            NUM_GN_GROUPS=32,\n",
      "            OUT_CONV_KERNEL_SIZE=1,\n",
      "            NUM_CLASSES=13,\n",
      "            ROT_CLASS_AWARE=False,\n",
      "            XYZ_LOSS_TYPE='L1',\n",
      "            XYZ_LOSS_MASK_GT='visib',\n",
      "            XYZ_LW=1.0,\n",
      "            NORM_LOSS_TYPE='L1',\n",
      "            NORM_LOSS_MASK_GT='visib',\n",
      "            NORM_LW=1.0,\n",
      "            MASK_CLASS_AWARE=False,\n",
      "            MASK_LOSS_TYPE='L1',\n",
      "            MASK_LOSS_GT='trunc',\n",
      "            MASK_LW=1.0,\n",
      "            MASK_THR_TEST=0.5,\n",
      "            NUM_REGIONS=64,\n",
      "            REGION_CLASS_AWARE=False,\n",
      "            REGION_LOSS_TYPE='CE',\n",
      "            REGION_LOSS_MASK_GT='visib',\n",
      "            REGION_LW=1.0,\n",
      "            CROSS_NORM_LOSS_TYPE='L1',\n",
      "            CROSS_NORM_LW=1.0,\n",
      "            CROSS_NORM_LOSS_START=0.3,\n",
      "            RECTIFY_NORM=True),\n",
      "        PNP_NET=dict(\n",
      "            FREEZE=False,\n",
      "            R_ONLY=False,\n",
      "            T_ONLY=True,\n",
      "            LR_MULT=1.0,\n",
      "            PNP_HEAD_CFG=dict(\n",
      "                type='ConvPnPNet', norm='GN', num_gn_groups=32, drop_prob=0.0),\n",
      "            WITH_2D_COORD=True,\n",
      "            COORD_TYPE='abs',\n",
      "            REGION_ATTENTION=True, #TODO\n",
      "            MASK_ATTENTION='none',\n",
      "            TRANS_WITH_BOX_INFO='none',\n",
      "            ROT_TYPE='allo_rot6d',\n",
      "            TRANS_TYPE='centroid_z',\n",
      "            Z_TYPE='REL',\n",
      "            NUM_PM_POINTS=3000,\n",
      "            PM_LOSS_TYPE='L1',\n",
      "            PM_SMOOTH_L1_BETA=1.0,\n",
      "            PM_LOSS_SYM=False,\n",
      "            PM_NORM_BY_EXTENT=True,\n",
      "            PM_R_ONLY=True,\n",
      "            PM_DISENTANGLE_T=False,\n",
      "            PM_DISENTANGLE_Z=False,\n",
      "            PM_T_USE_POINTS=False,\n",
      "            PM_LW=0.0,\n",
      "            ROT_LOSS_TYPE='angular',\n",
      "            ROT_LW=0.0,\n",
      "            CENTROID_LOSS_TYPE='L1',\n",
      "            CENTROID_LW=8.0,\n",
      "            Z_LOSS_TYPE='L1',\n",
      "            Z_LW=1.0,\n",
      "            TRANS_LOSS_TYPE='L1',\n",
      "            TRANS_LOSS_DISENTANGLE=True,\n",
      "            TRANS_LW=0.0,\n",
      "            BIND_LOSS_TYPE='L1',\n",
      "            BIND_LW=0.0,\n",
      "            CROSS_R_LOSS_TYPE='L1',\n",
      "            CROSS_R_LW=0,\n",
      "            CROSS_R_LOSS_START=1.0),\n",
      "        SVD_NET=dict(\n",
      "            ENABLE=True,\n",
      "            FREEZE=False,\n",
      "            LR_MULT=1.0,\n",
      "            SVD_HEAD_CFG=dict(\n",
      "                type='ConvSVDNet', norm='GN', num_gn_groups=32, drop_prob=0.0),\n",
      "            WITH_2D_COORD=False,\n",
      "            REGION_ATTENTION=True,\n",
      "            MASK_ATTENTION='none',\n",
      "            ROT_TYPE='allo_rot6d',\n",
      "            NUM_PM_POINTS=3000,\n",
      "            PM_LOSS_TYPE='L1',\n",
      "            PM_SMOOTH_L1_BETA=1.0,\n",
      "            PM_LOSS_SYM=False,\n",
      "            PM_NORM_BY_EXTENT=True,\n",
      "            PM_R_ONLY=True,\n",
      "            PM_DISENTANGLE_T=False,\n",
      "            PM_DISENTANGLE_Z=False,\n",
      "            PM_T_USE_POINTS=False,\n",
      "            PM_LW=4.0,\n",
      "            ROT_LOSS_TYPE='angular',\n",
      "            ROT_LW=0.0,\n",
      "            CROSS_R_LOSS_TYPE='L1',\n",
      "            CROSS_R_LW=1.0,\n",
      "            CROSS_R_LOSS_START=0.3),\n",
      "        TRANS_HEAD=dict(\n",
      "            ENABLED=False,\n",
      "            FREEZE=True,\n",
      "            LR_MULT=1.0,\n",
      "            NUM_LAYERS=3,\n",
      "            NUM_FILTERS=256,\n",
      "            NORM='BN',\n",
      "            NUM_GN_GROUPS=32,\n",
      "            CONV_KERNEL_SIZE=3,\n",
      "            OUT_CHANNEL=3,\n",
      "            TRANS_TYPE='centroid_z',\n",
      "            Z_TYPE='REL',\n",
      "            CENTROID_LOSS_TYPE='L1',\n",
      "            CENTROID_LW=0.0,\n",
      "            Z_LOSS_TYPE='L1',\n",
      "            Z_LW=0.0,\n",
      "            TRANS_LOSS_TYPE='L1',\n",
      "            TRANS_LW=0.0)),\n",
      "    KEYPOINT_ON=False,\n",
      "    LOAD_PROPOSALS=False)\n",
      "EXP_ID = 'airplane'\n",
      "RESUME = False\n",
      "\n",
      "\u001b[32m[10/19 02:32:54 detectron2]: \u001b[0mRunning with full config:\n",
      "Config (path: /home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/airplane.py): {'OUTPUT_ROOT': '/home/tianyou_zhang/Project/NVR-Net/gdr_normal_NVR_Net/', 'OUTPUT_DIR': '/home/tianyou_zhang/Project/NVR-Net/gdr_normal_NVR_Net/output/gdrn/airplane/a6_cPnP_airplane_norm_23', 'EXP_NAME': '', 'DEBUG': False, 'SEED': -1, 'CUDNN_BENCHMARK': True, 'VIS_PERIOD': 0, 'INPUT': {'FORMAT': 'BGR', 'MIN_SIZE_TRAIN': (1080,), 'MAX_SIZE_TRAIN': 1920, 'MIN_SIZE_TRAIN_SAMPLING': 'choice', 'MIN_SIZE_TEST': 1080, 'MAX_SIZE_TEST': 1920, 'WITH_DEPTH': False, 'AUG_DEPTH': False, 'COLOR_AUG_PROB': 0.0, 'COLOR_AUG_TYPE': 'code', 'COLOR_AUG_CODE': 'Sequential([Sometimes(0.4, CoarseDropout( p=0.1, size_percent=0.05) ),Sometimes(0.5, GaussianBlur(np.random.rand())),Sometimes(0.5, Add((-20, 20), per_channel=0.3)),Sometimes(0.4, Invert(0.20, per_channel=True)),Sometimes(0.5, Multiply((0.7, 1.4), per_channel=0.8)),Sometimes(0.5, Multiply((0.7, 1.4))),Sometimes(0.5, ContrastNormalization((0.5, 2.0), per_channel=0.3))], random_order=False)', 'COLOR_AUG_SYN_ONLY': False, 'BG_TYPE': 'coco', 'BG_IMGS_ROOT': 'datasets/background/', 'NUM_BG_IMGS': 10000, 'CHANGE_BG_PROB': 0.5, 'TRUNCATE_FG': False, 'BG_KEEP_ASPECT_RATIO': True, 'DZI_TYPE': 'uniform', 'DZI_PAD_SCALE': 1.2, 'DZI_SCALE_RATIO': 0.025, 'DZI_SHIFT_RATIO': 0.025, 'SMOOTH_XYZ': False, 'SMOOTH_NORM': False, 'VIDEO': None, 'FLIP_PROB': 0.5, 'FIXED_FOCAL_LENGTH': 100, 'XY_SCALE_RATIO': 1, 'Z_SCALE_RATIO': 0.001}, 'DATASETS': {'TRAIN': ('airplane',), 'TRAIN2': (), 'TRAIN2_RATIO': 0.0, 'PROPOSAL_FILES_TRAIN': (), 'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000, 'TEST': ('airplane',), 'PROPOSAL_FILES_TEST': (), 'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000, 'DET_FILES_TEST': ('/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/you3/bbox.json',), 'DET_TOPK_PER_OBJ': 1, 'DET_THR': 0.0, 'SYM_OBJS': []}, 'DATALOADER': {'NUM_WORKERS': 32, 'ASPECT_RATIO_GROUPING': False, 'SAMPLER_TRAIN': 'TrainingSampler', 'REPEAT_THRESHOLD': 0.0, 'FILTER_EMPTY_ANNOTATIONS': True, 'FILTER_EMPTY_DETS': True, 'FILTER_VISIB_THR': 0.0}, 'SOLVER': {'IMS_PER_BATCH': 48, 'TOTAL_EPOCHS': 960, 'OPTIMIZER_CFG': {'type': 'Ranger', 'lr': 0.0001, 'weight_decay': 0}, 'GAMMA': 0.1, 'BIAS_LR_FACTOR': 1.0, 'LR_SCHEDULER_NAME': 'flat_and_anneal', 'WARMUP_METHOD': 'linear', 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'ANNEAL_METHOD': 'cosine', 'ANNEAL_POINT': 0.3, 'POLY_POWER': 0.9, 'REL_STEPS': (0.5, 0.75), 'CHECKPOINT_PERIOD': 20, 'CHECKPOINT_BY_EPOCH': True, 'MAX_TO_KEEP': 1, 'AMP': {'ENABLED': False}, 'WEIGHT_DECAY': 0, 'OPTIMIZER_NAME': 'Ranger', 'BASE_LR': 0.0001, 'MOMENTUM': 0.9}, 'TRAIN': {'PRINT_FREQ': 100, 'VERBOSE': False, 'VIS': False, 'VIS_IMG': False}, 'VAL': {'DATASET_NAME': 'lm', 'SCRIPT_PATH': 'lib/pysixd/scripts/eval_pose_results_more.py', 'RESULTS_PATH': '', 'TARGETS_FILENAME': 'lm_test_targets_bb8.json', 'ERROR_TYPES': 'ad,rete,re,te,proj', 'RENDERER_TYPE': 'cpp', 'SPLIT': 'test', 'SPLIT_TYPE': 'bb8', 'N_TOP': 1, 'EVAL_CACHED': False, 'SCORE_ONLY': False, 'EVAL_PRINT_ONLY': False, 'EVAL_PRECISION': False, 'USE_BOP': False}, 'TEST': {'EVAL_PERIOD': 0, 'VIS': False, 'TEST_BBOX_TYPE': 'est', 'PRECISE_BN': {'ENABLED': False, 'NUM_ITER': 200}, 'AMP_TEST': False, 'USE_PNP': False, 'PNP_TYPE': 'ransac_pnp', 'OUTPUT_INTERMEDIATE_FEATURE': False, 'USE_SVD': False, 'SVD_TYPE': 'all_once', 'SAVE_NORMAL': False}, 'MODEL': {'DEVICE': 'cuda', 'WEIGHTS': '', 'PIXEL_MEAN': [0.0, 0.0, 0.0], 'PIXEL_STD': [255.0, 255.0, 255.0], 'LOAD_DETS_TEST': True, 'CDPN': {'NAME': 'GDRN', 'TASK': 'rot', 'USE_MTL': False, 'BACKBONE': {'PRETRAINED': 'torchvision://resnet18', 'ARCH': 'resnet', 'NUM_LAYERS': 18, 'INPUT_CHANNEL': 3, 'INPUT_RES': 256, 'OUTPUT_RES': 64, 'FREEZE': False}, 'ROT_HEAD': {'FREEZE': False, 'ROT_CONCAT': False, 'XYZ_BIN': 64, 'NUM_LAYERS': 3, 'NUM_FILTERS': 256, 'CONV_KERNEL_SIZE': 3, 'NORM': 'BN', 'NUM_GN_GROUPS': 32, 'OUT_CONV_KERNEL_SIZE': 1, 'NUM_CLASSES': 13, 'ROT_CLASS_AWARE': False, 'XYZ_LOSS_TYPE': 'L1', 'XYZ_LOSS_MASK_GT': 'visib', 'XYZ_LW': 1.0, 'NORM_LOSS_TYPE': 'L1', 'NORM_LOSS_MASK_GT': 'visib', 'NORM_LW': 1.0, 'MASK_CLASS_AWARE': False, 'MASK_LOSS_TYPE': 'L1', 'MASK_LOSS_GT': 'trunc', 'MASK_LW': 1.0, 'MASK_THR_TEST': 0.5, 'NUM_REGIONS': 64, 'REGION_CLASS_AWARE': False, 'REGION_LOSS_TYPE': 'CE', 'REGION_LOSS_MASK_GT': 'visib', 'REGION_LW': 1.0, 'CROSS_NORM_LOSS_TYPE': 'L1', 'CROSS_NORM_LW': 1.0, 'CROSS_NORM_LOSS_START': 0.3, 'RECTIFY_NORM': True}, 'PNP_NET': {'FREEZE': False, 'R_ONLY': False, 'T_ONLY': True, 'LR_MULT': 1.0, 'PNP_HEAD_CFG': {'type': 'ConvPnPNet', 'norm': 'GN', 'num_gn_groups': 32, 'drop_prob': 0.0}, 'WITH_2D_COORD': True, 'COORD_TYPE': 'abs', 'REGION_ATTENTION': True, 'MASK_ATTENTION': 'none', 'TRANS_WITH_BOX_INFO': 'none', 'ROT_TYPE': 'allo_rot6d', 'TRANS_TYPE': 'centroid_z', 'Z_TYPE': 'REL', 'NUM_PM_POINTS': 3000, 'PM_LOSS_TYPE': 'L1', 'PM_SMOOTH_L1_BETA': 1.0, 'PM_LOSS_SYM': False, 'PM_NORM_BY_EXTENT': True, 'PM_R_ONLY': True, 'PM_DISENTANGLE_T': False, 'PM_DISENTANGLE_Z': False, 'PM_T_USE_POINTS': False, 'PM_LW': 0.0, 'ROT_LOSS_TYPE': 'angular', 'ROT_LW': 0.0, 'CENTROID_LOSS_TYPE': 'L1', 'CENTROID_LW': 8.0, 'Z_LOSS_TYPE': 'L1', 'Z_LW': 1.0, 'TRANS_LOSS_TYPE': 'L1', 'TRANS_LOSS_DISENTANGLE': True, 'TRANS_LW': 0.0, 'BIND_LOSS_TYPE': 'L1', 'BIND_LW': 0.0, 'CROSS_R_LOSS_TYPE': 'L1', 'CROSS_R_LW': 0, 'CROSS_R_LOSS_START': 1.0}, 'SVD_NET': {'ENABLE': True, 'FREEZE': False, 'LR_MULT': 1.0, 'SVD_HEAD_CFG': {'type': 'ConvSVDNet', 'norm': 'GN', 'num_gn_groups': 32, 'drop_prob': 0.0}, 'WITH_2D_COORD': False, 'REGION_ATTENTION': True, 'MASK_ATTENTION': 'none', 'ROT_TYPE': 'allo_rot6d', 'NUM_PM_POINTS': 3000, 'PM_LOSS_TYPE': 'L1', 'PM_SMOOTH_L1_BETA': 1.0, 'PM_LOSS_SYM': False, 'PM_NORM_BY_EXTENT': True, 'PM_R_ONLY': True, 'PM_DISENTANGLE_T': False, 'PM_DISENTANGLE_Z': False, 'PM_T_USE_POINTS': False, 'PM_LW': 4.0, 'ROT_LOSS_TYPE': 'angular', 'ROT_LW': 0.0, 'CROSS_R_LOSS_TYPE': 'L1', 'CROSS_R_LW': 1.0, 'CROSS_R_LOSS_START': 0.3}, 'TRANS_HEAD': {'ENABLED': False, 'FREEZE': True, 'LR_MULT': 1.0, 'NUM_LAYERS': 3, 'NUM_FILTERS': 256, 'NORM': 'BN', 'NUM_GN_GROUPS': 32, 'CONV_KERNEL_SIZE': 3, 'OUT_CHANNEL': 3, 'TRANS_TYPE': 'centroid_z', 'Z_TYPE': 'REL', 'CENTROID_LOSS_TYPE': 'L1', 'CENTROID_LW': 0.0, 'Z_LOSS_TYPE': 'L1', 'Z_LW': 0.0, 'TRANS_LOSS_TYPE': 'L1', 'TRANS_LW': 0.0}}, 'KEYPOINT_ON': False, 'LOAD_PROPOSALS': False}, 'EXP_ID': 'airplane', 'RESUME': False}\n",
      "\u001b[32m[10/19 02:32:55 detectron2]: \u001b[0mFull config saved to /home/tianyou_zhang/Project/NVR-Net/gdr_normal_NVR_Net/output/gdrn/airplane/a6_cPnP_airplane_norm_23/airplane.py\n",
      "\u001b[32m[10/19 02:32:55 d2.utils.env]: \u001b[0mUsing a generated random seed 55179861\n"
     ]
    }
   ],
   "source": [
    "# args = my_default_argument_parser().parse_args(['--config-file', 'output/gdrn/lm/a6_cPnP_lm13_norm_14/a6_cPnP_lm13_norm.py', '--num-gpus', '1'])\n",
    "# args = my_default_argument_parser().parse_args(['--config-file', 'configs/gdrn/ycbv/a6_cPnP_AugAAETrunc_BG0.5_Rsym_ycbv_real_pbr_visib20_10e_norm.py', '--num-gpus', '1'])\n",
    "args = my_default_argument_parser().parse_args(['--config-file', '/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/airplane.py', '--num-gpus', '1'])\n",
    "\n",
    "cfg = setup(args)\n",
    "# cfg.OUTPUT_DIR = 'debug/gdrn/ycbv/a6_cPnP_AugAAETrunc_BG0.5_Rsym_ycbv_real_pbr_visib20_10e_norm_test'\n",
    "cfg.OUTPUT_DIR = 'debug/gdrn/airplane/a6_cPnP_AugAAETrunc_BG0.5_lmo_real_pbr0.1_40e_norm_efficientpose/'\n",
    "cfg.TEST.USE_SVD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac7f01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:00<00:00, 78031.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1019_023257 core.utils.dataset_utils@130]: \u001b[0mLoading detections for airplane from: /home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/you3/bbox.json\n",
      "\u001b[5m\u001b[31mWRN\u001b[0m \u001b[32m[1019_023257 core.utils.dataset_utils@140]: \u001b[0mpop the original annotations, load detections\n",
      "\u001b[5m\u001b[31mWRN\u001b[0m \u001b[32m[1019_023257 core.utils.dataset_utils@112]: \u001b[0mRemoved 0 images with empty detections. 900 images left.\n",
      "\u001b[32m[1019_023257 core.gdrn_modeling.data_loader@176]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[1019_023257 core.gdrn_modeling.data_loader@181]: \u001b[0mSerialized dataset takes 0.45 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_meta = MetadataCatalog.get(cfg.DATASETS.TRAIN)\n",
    "train_dset_names = cfg.DATASETS.TRAIN[0]\n",
    "print(train_dset_names)\n",
    "data_loader = build_gdrn_test_loader(cfg, train_dset_names)\n",
    "data_loader_iter = iter(data_loader)\n",
    "# data = next(data_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5622c475",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e9d90f370bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdrn_modeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGDRN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDPN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_checkpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMyCheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/models/GDRN.py\u001b[0m in \u001b[0;36mbuild_model_optimizer\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mpnp_head_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnp_net_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPNP_HEAD_CFG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mpnp_head_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnp_head_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpnp_head_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ConvPnPNet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             pnp_head_cfg.update(\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "from core.gdrn_modeling.models import GDRN\n",
    "model, optimizer = eval(cfg.MODEL.CDPN.NAME).build_model_optimizer(cfg)\n",
    "\n",
    "from core.utils.my_checkpoint import MyCheckpointer\n",
    "from torch.cuda.amp import GradScaler\n",
    "import core.utils.my_comm as comm\n",
    "cfg.MODEL.WEIGHTS = '/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/model_final.pth'\n",
    "# cfg.MODEL.WEIGHTS = '/home/fgkun/projects/GDR-Net/output/gdrn/lmo/a6_cPnP_AugAAETrunc_BG0.5_lmo_real_pbr0.1_40e_norm_1/model_final.pth'\n",
    "# cfg.MODEL.WEIGHTS = '/home/fgkun/projects/GDR-Net/output/gdrn/lm/a6_cPnP_lm13_norm_4/model_0102399.pth'\n",
    "from core.utils import solver_utils\n",
    "scheduler = solver_utils.build_lr_scheduler(cfg, optimizer, total_iters=1)\n",
    "AMP_ON = cfg.SOLVER.AMP.ENABLED\n",
    "grad_scaler = GradScaler()\n",
    "checkpointer = MyCheckpointer(\n",
    "        model,\n",
    "        cfg.OUTPUT_DIR,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        gradscaler=grad_scaler,\n",
    "        save_to_disk=comm.is_main_process(),\n",
    "    )\n",
    "start_iter = checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=True).get(\"iteration\", -1) + 1\n",
    "\n",
    "model.eval()\n",
    "\n",
    "from core.gdrn_modeling.engine_utils import batch_data, batch_data_test\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56696b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:02, 44.88it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 5.93 GiB already allocated; 10.50 MiB free; 5.93 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0dd38562c0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mresize_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resize_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mroi_coord_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roi_coord_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mroi_extents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roi_extent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/models/GDRN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gt_norm, gt_norm_bin, gt_mask_trunc, gt_mask_visib, gt_mask_obj, gt_region, gt_allo_quat, gt_ego_quat, gt_allo_rot6d, gt_ego_rot6d, gt_ego_rot, gt_points, sym_infos, gt_trans, gt_trans_ratio, roi_classes, roi_coord_2d, roi_cams, roi_centers, roi_whs, roi_extents, resize_ratios, do_loss, gt_allo_rot, num_epoch)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# features.shape [bs, 2048, 8, 8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# joints.shape [bs, 1152, 64, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_stc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_stc_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_stc_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_dyn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_dyn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_dyn_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot_head_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# TODO: remove this trans_head_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/models/cdpn_rot_head_region.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_f64, x_f32, x_f16)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_output_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_output_dim\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_output_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot_output_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 5.93 GiB already allocated; 10.50 MiB free; 5.93 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for img_index, data in tqdm(enumerate(data_loader_iter)):\n",
    "    batch = batch_data_test(cfg, data)\n",
    "    with autocast(enabled=cfg.TEST.AMP_TEST):\n",
    "        out_dict = model(\n",
    "            batch[\"roi_img\"],\n",
    "            roi_classes=batch[\"roi_cls\"],\n",
    "            roi_cams=batch[\"roi_cam\"],\n",
    "            roi_whs=batch[\"roi_wh\"],\n",
    "            roi_centers=batch[\"roi_center\"],\n",
    "            resize_ratios=batch[\"resize_ratio\"],\n",
    "            roi_coord_2d=batch.get(\"roi_coord_2d\", None),\n",
    "            roi_extents=batch.get(\"roi_extent\", None),\n",
    "        )\n",
    "    output.append(out_dict[\"trans\"].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7e9397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.TEST.AMP_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e577b6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ccffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23594572",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a1c380b7d9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/.conda/envs/pytorch1.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;31m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(data_loader_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b803d800",
   "metadata": {},
   "source": [
    "## Rewrite .txt to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44723df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "txt_file = \"/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/zuo3/bbox.txt\"\n",
    "json_file = \"/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/zuo3/bbox.json\"\n",
    "\n",
    "out_line = {}\n",
    "with open(txt_file, 'r') as in_file:\n",
    "    with open(json_file, 'w') as out_file:\n",
    "        for line in in_file:\n",
    "            in_line = line.strip('\\n').split(' ')            \n",
    "            id, _, left_x, _, top_y, _, w, _, h = in_line\n",
    "            out_line[\"{:d}/{:d}\".format(int(0), int(id))]=[{\"obj_id\": int(0), \"bbox_est\":[float(left_x), float(top_y), float(w), float(h)], \"score\": int(1)}]\n",
    "            # json.loads(out_line)\n",
    "        json.dump(out_line, out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8978993f",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c71621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:00<00:00, 74714.46it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-575ef0ad007e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dset_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gdrn_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dset_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_loader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/data_loader.py\u001b[0m in \u001b[0;36mbuild_gdrn_train_loader\u001b[0;34m(cfg, dataset_names)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mfilter_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILTER_EMPTY_ANNOTATIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mmin_keypoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROI_KEYPOINT_HEAD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_KEYPOINTS_PER_IMAGE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEYPOINT_ON\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0mproposal_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROPOSAL_FILES_TRAIN\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_PROPOSALS\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m     )\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(dataset_names, filter_empty, min_keypoints, proposal_files)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mhas_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"annotations\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilter_empty\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_instances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_images_with_only_crowd_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_keypoints\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_instances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_images_with_few_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36mfilter_images_with_only_crowd_annotations\u001b[0;34m(dataset_dicts)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dicts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mnum_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dicts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mnum_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(anns)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iscrowd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "dataset_meta = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "train_dset_names = cfg.DATASETS.TRAIN\n",
    "data_loader = build_gdrn_train_loader(cfg, train_dset_names)\n",
    "data_loader_iter = iter(data_loader)\n",
    "    \n",
    "train_2_dset_names = cfg.DATASETS.get(\"TRAIN2\", ())\n",
    "train_2_ratio = cfg.DATASETS.get(\"TRAIN2_RATIO\", 0.0)\n",
    "if train_2_ratio > 0.0 and len(train_2_dset_names) > 0:\n",
    "    data_loader_2 = build_gdrn_train_loader(cfg, train_2_dset_names)\n",
    "    data_loader_2_iter = iter(data_loader_2)\n",
    "else:\n",
    "    data_loader_2 = None\n",
    "    data_loader_2_iter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7afc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.random.rand() < train_2_ratio:\n",
    "    data = next(data_loader_2_iter)\n",
    "else:\n",
    "    data = next(data_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b50e6c-b4ca-497b-9e12-f8c548c554e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "#     data = next(data_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8344246-fbbe-4a06-97a1-950f5e5b7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "#     data = next(data_loader_2_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_img = data[0]['roi_img'].cpu().numpy().transpose([1,2,0])\n",
    "roi_mask_visib = data[0]['roi_mask_visib'].cpu().numpy()\n",
    "roi_norm = data[0]['roi_norm'].cpu().numpy()\n",
    "roi_stc_norm = roi_norm[:3].transpose([1,2,0])\n",
    "roi_dyn_norm = roi_norm[3:].transpose([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(24,4, figsize=(16,96))\n",
    "for i,d in enumerate(data):\n",
    "    roi_img = d['roi_img'].cpu().numpy().transpose([1,2,0])\n",
    "    roi_mask_visib = d['roi_mask_visib'].cpu().numpy()\n",
    "    roi_norm = d['roi_norm'].cpu().numpy()\n",
    "    roi_stc_norm = roi_norm[:3].transpose([1,2,0])\n",
    "    roi_dyn_norm = roi_norm[3:].transpose([1,2,0])\n",
    "    axs[i,0].imshow(roi_img)\n",
    "    axs[i,0].set_title('{}'.format(i))\n",
    "    axs[i,1].imshow(roi_mask_visib)\n",
    "    axs[i,2].imshow(roi_stc_norm)\n",
    "    axs[i,3].imshow(roi_dyn_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,d['file_name']) for i,d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756383a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "data[i].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_R(stc, dyn, weight=None):\n",
    "    if isinstance(weight, np.ndarray):\n",
    "        weight = weight.reshape([-1])\n",
    "        assert weight.shape[0] == stc.shape[0], 'weight size not match!'\n",
    "        W = np.diag(weight)\n",
    "    else:\n",
    "        W = np.eye(stc.shape[0])\n",
    "    AA = stc.T.dot(W).dot(dyn)\n",
    "    U, S, VH = np.linalg.svd(AA)\n",
    "    R_matrix = VH.T.dot(U.T)\n",
    "    return R_matrix\n",
    "\n",
    "def re(R_est, R_gt):\n",
    "    from scipy.linalg import logm\n",
    "    import numpy.linalg as LA\n",
    "    assert (R_est.shape == R_gt.shape == (3, 3))\n",
    "    temp = logm(np.dot(np.transpose(R_est), R_gt))\n",
    "    rd_rad = LA.norm(temp, 'fro') / np.sqrt(2)\n",
    "    rd_deg = rd_rad / np.pi * 180\n",
    "    return rd_deg\n",
    "\n",
    "roi_mask_visib = data[i]['roi_mask_visib'].cpu().numpy()\n",
    "roi_norm = data[i]['roi_norm'].cpu().numpy()\n",
    "idx = np.where(roi_mask_visib>0)\n",
    "# stc_norm = roi_norm[:3].transpose([1,2,0])[idx]\n",
    "# dyn_norm = roi_norm[3:].transpose([1,2,0])[idx]\n",
    "stc_norm = (roi_norm[:3].transpose([1,2,0])[idx]-0.5)*2\n",
    "dyn_norm = (roi_norm[3:].transpose([1,2,0])[idx]-0.5)*2\n",
    "norm_rot = cal_R(stc_norm, dyn_norm)\n",
    "print(norm_rot)\n",
    "\n",
    "part_allo_rot = data[i]['allo_rot6d'].cpu().numpy()\n",
    "gt_allo_rot = np.zeros([3,3])\n",
    "gt_allo_rot[:3,0] = part_allo_rot[:3]\n",
    "gt_allo_rot[:3,1] = part_allo_rot[3:]\n",
    "gt_allo_rot[:3,2] = np.cross(part_allo_rot[:3], part_allo_rot[3:])\n",
    "print(re(gt_allo_rot, norm_rot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils.utils import egocentric_to_allocentric_gl, CV2GL\n",
    "def SkewSymRotm(a,b,c):\n",
    "    return np.array([\n",
    "        [0, -c, b],\n",
    "        [c, 0, -a],\n",
    "        [-b, a, 0]\n",
    "    ])\n",
    "\n",
    "def SkewSymRotmv(u):\n",
    "    a,b,c = u.reshape(3).tolist()\n",
    "    return SkewSymRotm(a,b,c)\n",
    "\n",
    "def Axis2Rotm(ang, axis):\n",
    "    axis = -axis if ang < 0 else axis\n",
    "    ang = -ang if ang < 0 else ang\n",
    "    axis = axis/np.linalg.norm(axis)\n",
    "    sw = SkewSymRotmv(axis)\n",
    "    return np.eye(3)-sw*np.sin(ang)+sw.dot(sw)*(1-np.cos(ang))\n",
    "def ang_rectify(trans, reverse=False):\n",
    "    if np.linalg.norm(trans[:2]) < np.abs(trans[-1])/1e8:\n",
    "        return np.eye(3)\n",
    "    ang = np.arctan(np.linalg.norm(trans[:2]/trans[-1]))\n",
    "    axis = np.array([-trans[1], trans[0], 0]) if trans[0]>=0 else np.array([trans[1], -trans[0], 0])\n",
    "    theta = ang if trans[0]>=0 else -ang\n",
    "    if reverse:\n",
    "        return Axis2Rotm(theta, axis).T\n",
    "    else:\n",
    "        return Axis2Rotm(theta, axis)\n",
    "CV2GL.dot(ang_rectify(data[i]['trans'])).dot(CV2GL).dot(data[i]['ego_rot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_pose = np.zeros([3,4])\n",
    "ego_pose[:3,:3] = data[i]['ego_rot']\n",
    "ego_pose[:3,3] = data[i]['trans']\n",
    "egocentric_to_allocentric_gl(ego_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506eb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[i]['ego_rot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d887658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[i]['allo_rot6d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "\u001b[32m[1019_005541 core.gdrn_modeling.models.GDRN@961]: \u001b[0mload backbone weights from: torchvision://resnet18\n",
      "\u001b[32m[1019_005541 core.gdrn_modeling.models.GDRN@101]: \u001b[0mUse load_from_torchvision loader\n",
      "\u001b[5m\u001b[31mWRN\u001b[0m \u001b[32m[1019_005541 core.gdrn_modeling.models.GDRN@104]: \u001b[0mThe model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from core.gdrn_modeling.models import GDRN\n",
    "model, optimizer = eval(cfg.MODEL.CDPN.NAME).build_model_optimizer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb59faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/19 00:55:45 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "from core.utils.my_checkpoint import MyCheckpointer\n",
    "from torch.cuda.amp import GradScaler\n",
    "import core.utils.my_comm as comm\n",
    "cfg.MODEL.WEIGHTS = '/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/output/a6_cPnP_airplane_norm_23_debug/model_final.pth'\n",
    "# cfg.MODEL.WEIGHTS = '/home/fgkun/projects/GDR-Net/output/gdrn/lmo/a6_cPnP_AugAAETrunc_BG0.5_lmo_real_pbr0.1_40e_norm_1/model_final.pth'\n",
    "# cfg.MODEL.WEIGHTS = '/home/fgkun/projects/GDR-Net/output/gdrn/lm/a6_cPnP_lm13_norm_4/model_0102399.pth'\n",
    "from core.utils import solver_utils\n",
    "scheduler = solver_utils.build_lr_scheduler(cfg, optimizer, total_iters=1)\n",
    "grad_scaler = GradScaler()\n",
    "checkpointer = MyCheckpointer(\n",
    "        model,\n",
    "        cfg.OUTPUT_DIR,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        gradscaler=grad_scaler,\n",
    "        save_to_disk=comm.is_main_process(),\n",
    "    )\n",
    "start_iter = checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=True).get(\"iteration\", -1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15564dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.gdrn_modeling.engine_utils import batch_data, batch_data_test\n",
    "from detectron2.utils.events import EventStorage\n",
    "data = next(data_loader_iter)\n",
    "with EventStorage(start_iter) as storage:\n",
    "    batch = batch_data_test(cfg, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'im_H': tensor([1080.], device='cuda:0'), 'im_W': tensor([1418.], device='cuda:0'), 'roi_img': tensor([[[[0.7451, 0.7451, 0.7451,  ..., 0.7490, 0.7451, 0.7451],\n",
      "          [0.7451, 0.7451, 0.7451,  ..., 0.7451, 0.7451, 0.7451],\n",
      "          [0.7451, 0.7451, 0.7451,  ..., 0.7490, 0.7451, 0.7451],\n",
      "          ...,\n",
      "          [0.7412, 0.7373, 0.7373,  ..., 0.7373, 0.7412, 0.7412],\n",
      "          [0.7373, 0.7373, 0.7373,  ..., 0.7412, 0.7412, 0.7412],\n",
      "          [0.7373, 0.7373, 0.7373,  ..., 0.7412, 0.7412, 0.7412]],\n",
      "\n",
      "         [[0.8118, 0.8157, 0.8118,  ..., 0.8157, 0.8157, 0.8118],\n",
      "          [0.8118, 0.8118, 0.8118,  ..., 0.8118, 0.8118, 0.8118],\n",
      "          [0.8118, 0.8118, 0.8118,  ..., 0.8157, 0.8157, 0.8118],\n",
      "          ...,\n",
      "          [0.8157, 0.8157, 0.8157,  ..., 0.8157, 0.8157, 0.8157],\n",
      "          [0.8157, 0.8118, 0.8157,  ..., 0.8157, 0.8157, 0.8157],\n",
      "          [0.8157, 0.8118, 0.8157,  ..., 0.8157, 0.8157, 0.8157]],\n",
      "\n",
      "         [[0.8745, 0.8784, 0.8745,  ..., 0.8784, 0.8745, 0.8745],\n",
      "          [0.8745, 0.8745, 0.8745,  ..., 0.8745, 0.8745, 0.8745],\n",
      "          [0.8745, 0.8745, 0.8745,  ..., 0.8784, 0.8784, 0.8745],\n",
      "          ...,\n",
      "          [0.8902, 0.8902, 0.8902,  ..., 0.8902, 0.8941, 0.8941],\n",
      "          [0.8902, 0.8902, 0.8902,  ..., 0.8941, 0.8902, 0.8902],\n",
      "          [0.8902, 0.8902, 0.8902,  ..., 0.8941, 0.8902, 0.8902]]]],\n",
      "       device='cuda:0'), 'inst_id': tensor([0.], device='cuda:0'), 'roi_coord_2d': tensor([[[[0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592],\n",
      "          [0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592],\n",
      "          [0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592],\n",
      "          ...,\n",
      "          [0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592],\n",
      "          [0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592],\n",
      "          [0.4412, 0.4431, 0.4450,  ..., 0.5554, 0.5573, 0.5592]],\n",
      "\n",
      "         [[0.4007, 0.4007, 0.4007,  ..., 0.4007, 0.4007, 0.4007],\n",
      "          [0.4031, 0.4031, 0.4031,  ..., 0.4031, 0.4031, 0.4031],\n",
      "          [0.4056, 0.4056, 0.4056,  ..., 0.4056, 0.4056, 0.4056],\n",
      "          ...,\n",
      "          [0.5506, 0.5506, 0.5506,  ..., 0.5506, 0.5506, 0.5506],\n",
      "          [0.5531, 0.5531, 0.5531,  ..., 0.5531, 0.5531, 0.5531],\n",
      "          [0.5555, 0.5555, 0.5555,  ..., 0.5555, 0.5555, 0.5555]]]],\n",
      "       device='cuda:0'), 'roi_cls': tensor([0], device='cuda:0'), 'score': tensor([1.], device='cuda:0'), 'roi_extent': tensor([], device='cuda:0'), 'bbox_est': tensor([[639.3565, 492.9868, 780.8367, 541.4040]], device='cuda:0'), 'bbox_mode': tensor([0.], device='cuda:0'), 'roi_wh': tensor([[141.4802,  48.4171]], device='cuda:0'), 'scale': tensor([169.7762], device='cuda:0'), 'resize_ratio': tensor([0.3770], device='cuda:0'), 'roi_cam': tensor([[[2.0771e+07, 0.0000e+00, 7.0900e+02],\n",
      "         [0.0000e+00, 2.0769e+07, 5.4000e+02],\n",
      "         [0.0000e+00, 0.0000e+00, 1.0000e+00]]], device='cuda:0'), 'roi_center': tensor([[710.0966, 517.1954]], device='cuda:0'), 'scene_im_id': ['0/2'], 'file_name': ['/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/datasets/airplane/zuo3/1.png'], 'model_info': []}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dict = model(\n",
    "    batch[\"roi_img\"],\n",
    "    roi_classes=batch[\"roi_cls\"],\n",
    "    roi_cams=batch[\"roi_cam\"],\n",
    "    roi_whs=batch[\"roi_wh\"],\n",
    "    roi_centers=batch[\"roi_center\"],\n",
    "    resize_ratios=batch[\"resize_ratio\"],\n",
    "    # roi_coord_2d=None,\n",
    "    # roi_extents=None,\n",
    "    roi_coord_2d=batch.get(\"roi_coord_2d\", None),\n",
    "    roi_extents=batch.get(\"roi_extent\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a880e231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rot': tensor([[[ 0.9240, -0.3541, -0.1442],\n",
       "          [ 0.1335, -0.0545,  0.9895],\n",
       "          [-0.3582, -0.9336, -0.0031]]]),\n",
       " 'trans': tensor([[-1.4722e-07, -2.5213e-06,  3.8854e+00]], device='cuda:0',\n",
       "        grad_fn=<CatBackward>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731930a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trans_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-41a4aef85777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         data = next(data_loader_iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     out_dict = model(\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roi_img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/engine_utils.py\u001b[0m in \u001b[0;36mbatch_data\u001b[0;34m(cfg, data, device, phase)\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roi_trans_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trans_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# yapf: disable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     for key in [\n",
      "\u001b[0;32m/home/tianyou_zhang/Project/NVR-Net/gdr-normal-NVR-Net/core/gdrn_modeling/engine_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"roi_trans_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trans_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m# yapf: disable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     for key in [\n",
      "\u001b[0;31mKeyError\u001b[0m: 'trans_ratio'"
     ]
    }
   ],
   "source": [
    "from core.gdrn_modeling.engine_utils import batch_data\n",
    "from detectron2.utils.events import EventStorage\n",
    "with EventStorage(start_iter) as storage:\n",
    "#     if np.random.rand() < train_2_ratio:\n",
    "#         data = next(data_loader_2_iter)\n",
    "#     else:\n",
    "#         data = next(data_loader_iter)\n",
    "    batch = batch_data(cfg, data)\n",
    "    out_dict = model(\n",
    "        batch[\"roi_img\"],\n",
    "        gt_norm=batch.get(\"roi_norm\", None),\n",
    "        gt_norm_bin=batch.get(\"roi_norm_bin\", None),\n",
    "        gt_mask_trunc=batch[\"roi_mask_trunc\"],\n",
    "        gt_mask_visib=batch[\"roi_mask_visib\"],\n",
    "        gt_mask_obj=batch[\"roi_mask_obj\"],\n",
    "        gt_region=batch.get(\"roi_region\", None),\n",
    "        gt_allo_quat=batch.get(\"allo_quat\", None),\n",
    "        gt_ego_quat=batch.get(\"ego_quat\", None),\n",
    "        gt_allo_rot6d=batch.get(\"allo_rot6d\", None),\n",
    "        gt_ego_rot6d=batch.get(\"ego_rot6d\", None),\n",
    "        gt_allo_rot=batch.get(\"allo_rot\", None),\n",
    "        gt_ego_rot=batch.get(\"ego_rot\", None),\n",
    "        gt_trans=batch.get(\"trans\", None),\n",
    "        gt_trans_ratio=batch.get([\"roi_trans_ratio\"],None),\n",
    "        gt_points=batch.get(\"roi_points\", None),\n",
    "        sym_infos=batch.get(\"sym_info\", None),\n",
    "        roi_classes=batch[\"roi_cls\"],\n",
    "        roi_cams=batch[\"roi_cam\"],\n",
    "        roi_whs=batch[\"roi_wh\"],\n",
    "        roi_centers=batch[\"roi_center\"],\n",
    "        resize_ratios=batch[\"resize_ratio\"],\n",
    "        roi_coord_2d=batch.get(\"roi_coord_2d\", None),\n",
    "        roi_extents=batch.get(\"roi_extent\", None),\n",
    "        do_loss=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rot', 'trans'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce2a16-ad26-4849-9efc-0d4f759194fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1,3,figsize=(30,10))\n",
    "# axs[0].imshow(batch[\"roi_mask_trunc\"][0].cpu().numpy())\n",
    "# axs[1].imshow(batch[\"roi_mask_visib\"][0].cpu().numpy())\n",
    "# axs[2].imshow(batch[\"roi_mask_obj\"][0].cpu().numpy())\n",
    "ii = 6\n",
    "plt.imshow(np.stack([batch[\"roi_mask_trunc\"][ii].cpu().numpy(), batch[\"roi_mask_visib\"][ii].cpu().numpy(), batch[\"roi_mask_obj\"][ii].cpu().numpy()], axis=0).transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin = -1, vmax = 1)\n",
    "gt_mask_numpy = batch[\"roi_mask_visib\"][i].cpu().numpy()\n",
    "pred_norm_stc_x = gt_mask_numpy*out_dict['norm_stc_x'][i].detach().cpu().numpy()\n",
    "pred_norm_stc_y = gt_mask_numpy*out_dict['norm_stc_y'][i].detach().cpu().numpy()\n",
    "pred_norm_stc_z = gt_mask_numpy*out_dict['norm_stc_z'][i].detach().cpu().numpy()\n",
    "pred_norm_stc = np.concatenate([pred_norm_stc_x, pred_norm_stc_y, pred_norm_stc_z], axis=0)\n",
    "pred_norm_stc = pred_norm_stc.transpose([1,2,0])\n",
    "pred_norm_dyn_x = gt_mask_numpy*out_dict['norm_dyn_x'][i].detach().cpu().numpy()\n",
    "pred_norm_dyn_y = gt_mask_numpy*out_dict['norm_dyn_y'][i].detach().cpu().numpy()\n",
    "pred_norm_dyn_z = gt_mask_numpy*out_dict['norm_dyn_z'][i].detach().cpu().numpy()\n",
    "pred_norm_dyn = np.concatenate([pred_norm_dyn_x, pred_norm_dyn_y, pred_norm_dyn_z], axis=0)\n",
    "pred_norm_dyn = pred_norm_dyn.transpose([1,2,0])\n",
    "fig, axs = plt.subplots(4,4, figsize=(20,20))\n",
    "\n",
    "\n",
    "gt_stc_norm = roi_norm[:3].transpose([1,2,0])\n",
    "roi_norm_np = batch['roi_norm'][i].cpu().numpy()\n",
    "gt_stc_norm = roi_norm_np[:3].transpose([1,2,0])\n",
    "gt_stc_norm_x = gt_stc_norm[:,:,0]\n",
    "gt_stc_norm_y = gt_stc_norm[:,:,1]\n",
    "gt_stc_norm_z = gt_stc_norm[:,:,2]\n",
    "gt_dyn_norm = roi_norm_np[3:].transpose([1,2,0])\n",
    "gt_dyn_norm_x = gt_dyn_norm[:,:,0]\n",
    "gt_dyn_norm_y = gt_dyn_norm[:,:,1]\n",
    "gt_dyn_norm_z = gt_dyn_norm[:,:,2]\n",
    "\n",
    "axs[0,0].imshow(pred_norm_stc, norm=norm)\n",
    "axs[0,1].imshow(gt_stc_norm, norm=norm)\n",
    "axs[0,2].imshow(pred_norm_dyn, norm=norm)\n",
    "axs[0,3].imshow(gt_dyn_norm, norm=norm)\n",
    "\n",
    "axs[1,0].imshow(pred_norm_stc_x[0], norm=norm)\n",
    "axs[1,1].imshow(gt_stc_norm_x, norm=norm)\n",
    "axs[1,2].imshow(pred_norm_dyn_x[0], norm=norm)\n",
    "axs[1,3].imshow(gt_dyn_norm_x, norm=norm)\n",
    "\n",
    "axs[2,0].imshow(pred_norm_stc_y[0], norm=norm)\n",
    "axs[2,1].imshow(gt_stc_norm_y, norm=norm)\n",
    "axs[2,2].imshow(pred_norm_dyn_y[0], norm=norm)\n",
    "axs[2,3].imshow(gt_dyn_norm_y, norm=norm)\n",
    "\n",
    "axs[3,0].imshow(pred_norm_stc_z[0], norm=norm)\n",
    "axs[3,1].imshow(gt_stc_norm_z, norm=norm)\n",
    "axs[3,2].imshow(pred_norm_dyn_z[0], norm=norm)\n",
    "axs[3,3].imshow(gt_dyn_norm_z, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(gt_mask_numpy > 0)\n",
    "# pred_stc_norm = pred_norm_stc[idx]\n",
    "# pred_dyn_norm = pred_norm_dyn[idx]\n",
    "pred_stc_norm = (pred_norm_stc[idx]-0.5)*2\n",
    "pred_dyn_norm = (pred_norm_dyn[idx]-0.5)*2\n",
    "cal_R(pred_stc_norm, pred_dyn_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict['rot'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ea1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['allo_rot6d'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194d3ca-2045-4a90-b58c-234d1d970a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "allo_pose_numpy = batch['allo_rot'][i].cpu().numpy()\n",
    "gt_stc_norm_i = (gt_stc_norm-0.5)*2\n",
    "gt_dyn_norm_i = (gt_dyn_norm-0.5)*2\n",
    "tmp_idx = np.where(np.linalg.norm(gt_stc_norm_i, axis=-1)>0.5)\n",
    "gt_stc_norm_vec = gt_stc_norm_i[tmp_idx]\n",
    "gt_dyn_norm_vec = gt_dyn_norm_i[tmp_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325c81a-6ea5-4a5a-92c1-1a4778145c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs((allo_pose_numpy.dot(gt_stc_norm_vec.T)).T-gt_dyn_norm_vec))/np.shape(gt_stc_norm_vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3267213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import detectron2.utils.comm as comm\n",
    "gt_mask_norm = batch[\"roi_mask_visib\"]\n",
    "print(nn.L1Loss(reduction=\"sum\")(out_dict['norm_stc_x']*gt_mask_norm[:, None], batch['roi_norm'][:,:1]*gt_mask_norm[:, None]) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(nn.L1Loss(reduction=\"sum\")(out_dict['norm_stc_y']*gt_mask_norm[:, None], batch['roi_norm'][:,1:2]*gt_mask_norm[:, None]) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(nn.L1Loss(reduction=\"sum\")(out_dict['norm_stc_z']*gt_mask_norm[:, None], batch['roi_norm'][:,2:3]*gt_mask_norm[:, None]) / gt_mask_norm.sum().float().clamp(min=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def norm_pose_loss_dyn(base_loss, normal_stc, normal_dyn, allo_pose):\n",
    "    shape = normal_stc.size()\n",
    "    normal_dyn_pose = torch.bmm(allo_pose, (normal_stc.reshape([shape[0], 3,-1]))).reshape(shape)\n",
    "    loss = base_loss(normal_dyn, normal_dyn_pose.detach())\n",
    "    return loss\n",
    "\n",
    "def norm_pose_loss_stc(base_loss, normal_stc, normal_dyn, allo_pose):\n",
    "    shape = normal_stc.size()\n",
    "    normal_dyn_pose = torch.bmm(allo_pose, (normal_stc.reshape([shape[0], 3,-1]))).reshape(shape)\n",
    "    loss = base_loss(normal_dyn_pose, normal_dyn.detach())\n",
    "    return loss\n",
    "gt_mask_norm = batch[\"roi_mask_visib\"]\n",
    "out_stc_norm = torch.cat([(out_dict['norm_stc_x']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_stc_y']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_stc_z']-0.5)*2 * gt_mask_norm[:, None]], dim=1)\n",
    "out_dyn_norm = torch.cat([(out_dict['norm_dyn_x']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_dyn_y']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_dyn_z']-0.5)*2 * gt_mask_norm[:, None]], dim=1)\n",
    "gt_stc_norm = (batch['roi_norm'][:, :3]-0.5)*2\n",
    "gt_dyn_norm = (batch['roi_norm'][:, 3:]-0.5)*2\n",
    "print(norm_pose_loss_stc(nn.L1Loss(reduction=\"sum\"), out_stc_norm, out_dyn_norm, batch['allo_rot']) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(norm_pose_loss_dyn(nn.L1Loss(reduction=\"sum\"), out_stc_norm, out_dyn_norm, batch['allo_rot']) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(norm_pose_loss_stc(nn.L1Loss(reduction=\"sum\"), gt_stc_norm, gt_dyn_norm, batch['allo_rot']) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(norm_pose_loss_dyn(nn.L1Loss(reduction=\"sum\"), gt_stc_norm, gt_dyn_norm, batch['allo_rot']) / gt_mask_norm.sum().float().clamp(min=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask_norm = batch[\"roi_mask_visib\"]\n",
    "out_stc_norm = torch.cat([(out_dict['norm_stc_x']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_stc_y']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_stc_z']-0.5)*2 * gt_mask_norm[:, None]], dim=1)\n",
    "out_dyn_norm = torch.cat([(out_dict['norm_dyn_x']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_dyn_y']-0.5)*2 * gt_mask_norm[:, None], (out_dict['norm_dyn_z']-0.5)*2 * gt_mask_norm[:, None]], dim=1)\n",
    "gt_stc_norm = (batch['roi_norm'][:, :3]-0.5)*2\n",
    "gt_dyn_norm = (batch['roi_norm'][:, 3:]-0.5)*2\n",
    "shape = out_stc_norm.size()\n",
    "print(nn.L1Loss(reduction=\"sum\")(torch.bmm(out_dict['rot_allo'], out_stc_norm.reshape([shape[0], 3,-1])), out_dyn_norm.reshape([shape[0], 3,-1])) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(nn.L1Loss(reduction=\"sum\")(torch.bmm(out_dict['rot_allo'], gt_stc_norm.reshape([shape[0], 3,-1])), gt_dyn_norm.reshape([shape[0], 3,-1])) / gt_mask_norm.sum().float().clamp(min=1.0))\n",
    "print(nn.L1Loss(reduction=\"sum\")(torch.bmm(batch['allo_rot'], gt_stc_norm.reshape([shape[0], 3,-1])), gt_dyn_norm.reshape([shape[0], 3,-1])) / gt_mask_norm.sum().float().clamp(min=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = 13\n",
    "gt_mask_norm_np = gt_mask_norm[iii].cpu().numpy()\n",
    "pred_norm_stc_x_np = out_dict['norm_stc_x'][iii].detach().cpu().numpy()\n",
    "gt_norm_stc_x_np = batch['roi_norm'][iii,:1].cpu().numpy()\n",
    "np.mean(np.abs(pred_norm_stc_x_np-gt_norm_stc_x_np)[0][np.where(gt_mask_norm_np>0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8550f49-c62c-4a7f-a7d0-242036b65a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_norm_stc_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ab6f6-441d-4a32-aaef-4812956ffaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_norm_stc_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69af53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_dict['mask'].detach().cpu().numpy()[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e81d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1 ,2, figsize=(10,5))\n",
    "axs[0].imshow(np.argmax(out_dict['region'].detach().cpu().numpy()[i], axis=0)*gt_mask_norm.cpu().numpy()[i])\n",
    "axs[1].imshow(batch['roi_region'].cpu().numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventStorage(start_iter) as storage:\n",
    "    _, loss_dict = model(\n",
    "        batch[\"roi_img\"],\n",
    "        gt_norm=batch.get(\"roi_norm\", None),\n",
    "        gt_norm_bin=batch.get(\"roi_norm_bin\", None),\n",
    "        gt_mask_trunc=batch[\"roi_mask_trunc\"],\n",
    "        gt_mask_visib=batch[\"roi_mask_visib\"],\n",
    "        gt_mask_obj=batch[\"roi_mask_obj\"],\n",
    "        gt_region=batch.get(\"roi_region\", None),\n",
    "        gt_allo_quat=batch.get(\"allo_quat\", None),\n",
    "        gt_ego_quat=batch.get(\"ego_quat\", None),\n",
    "        gt_allo_rot6d=batch.get(\"allo_rot6d\", None),\n",
    "        gt_ego_rot6d=batch.get(\"ego_rot6d\", None),\n",
    "        gt_allo_rot=batch.get(\"allo_rot\", None),\n",
    "        gt_ego_rot=batch.get(\"ego_rot\", None),\n",
    "        gt_trans=batch.get(\"trans\", None),\n",
    "        gt_trans_ratio=batch[\"roi_trans_ratio\"],\n",
    "        gt_points=batch.get(\"roi_points\", None),\n",
    "        sym_infos=batch.get(\"sym_info\", None),\n",
    "        roi_classes=batch[\"roi_cls\"],\n",
    "        roi_cams=batch[\"roi_cam\"],\n",
    "        roi_whs=batch[\"roi_wh\"],\n",
    "        roi_centers=batch[\"roi_center\"],\n",
    "        resize_ratios=batch[\"resize_ratio\"],\n",
    "        roi_coord_2d=batch.get(\"roi_coord_2d\", None),\n",
    "        roi_extents=batch.get(\"roi_extent\", None),\n",
    "        num_epoch=160,\n",
    "        do_loss=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.CDPN.ROT_HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('pytorch1.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "35b5e47a1204516bb14c0e6c395314ea0bab3434fcd243336292317424b69190"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
